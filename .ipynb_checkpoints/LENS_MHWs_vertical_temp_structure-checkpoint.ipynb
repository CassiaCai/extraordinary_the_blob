{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee665857-2f93-40f0-9943-3afc73ea895d",
   "metadata": {},
   "source": [
    "# Composite vertical anomalous temperature structure of MHW events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b585c-6724-4037-a997-49b9f85dc532",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "To do: \n",
    "- Redo phases so that there are three phases\n",
    "- Make pcolormesh plots instead of contourf\n",
    "- Add variability/error indication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ae6e2-72b3-4815-bde1-f1ba21b5d19a",
   "metadata": {},
   "source": [
    "## 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9c041-3be2-43f4-8a9c-54bdb5f92abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e7f1b-8e78-4332-aa94-4095100f0bd8",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726e63e-f9b9-44d3-a229-18647c14882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [f'/glade/derecho/scratch/cassiacai/vertical_structure_events_ens_{i}.nc' for i in range(100)]\n",
    "all_events = xr.open_mfdataset(filepaths, combine='nested', concat_dim='event').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c460512-3f18-45d5-b381-d1a34ee43d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously stored MLD\n",
    "dataset = pq.ParquetDataset(\"HMXL_stats_0_100.parquet\")\n",
    "\n",
    "merged_df = dataset.read().to_pandas()\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "# 0 --> issue with 3 and 4\n",
    "# 1 --> issue with  2 and 3\n",
    "# 3 --> issue with  2 and 3\n",
    "\n",
    "merged_df.at[0, 'mean'] = np.delete(merged_df.at[0, 'mean'], [3])\n",
    "merged_df.at[1, 'mean'] = np.delete(merged_df.at[1, 'mean'], [2])\n",
    "merged_df.at[3, 'mean'] = np.delete(merged_df.at[3, 'mean'], [2])\n",
    "\n",
    "merged_df.at[0, 'max'] = np.delete(merged_df.at[0, 'max'], [3])\n",
    "merged_df.at[1, 'max'] = np.delete(merged_df.at[1, 'max'], [2])\n",
    "merged_df.at[3, 'max'] = np.delete(merged_df.at[3, 'max'], [2])\n",
    "\n",
    "# Flatten\n",
    "flattened_MLD = [item for sublist in merged_df['mean'] for item in sublist]\n",
    "max_flattened_MLD = [item for sublist in merged_df['max'] for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b30286-d5c4-43e7-9d14-5ac3df1f1e5e",
   "metadata": {},
   "source": [
    "## 2. Storing phases and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6bd9d-3380-4375-af5c-2a446d9b106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store ALL phases AND indices\n",
    "all_pre = []\n",
    "all_mid1 = []\n",
    "all_mid2 = []\n",
    "all_mid3 = []\n",
    "all_post = []\n",
    "all_ens_idx = []  # To store ensemble indices\n",
    "all_event_idx = []  # To store event indices\n",
    "mld_ls = []\n",
    "max_mld_ls = []\n",
    "# Loop through each event\n",
    "for event_id in range(all_events.data.shape[0]):\n",
    "    # Extract one event's data\n",
    "    event_data = all_events.isel(event=event_id).dropna(dim='time')\n",
    "    # Get total duration in months\n",
    "    total_months = event_data.sizes['time']\n",
    "    \n",
    "    # First 3 months are always PRE\n",
    "    pre = event_data.data.isel(time=slice(0, 3)).mean(dim='time')\n",
    "    \n",
    "    # Last 3 months are always POST\n",
    "    post = event_data.data.isel(time=slice(-3, None)).mean(dim='time')\n",
    "    \n",
    "    # Middle period (remaining months)\n",
    "    middle_data = event_data.data.isel(time=slice(3, -3))\n",
    "    middle_data_surf = event_data.data.isel(time=slice(3, -3)).isel(z_t = 0)\n",
    "\n",
    "    if len(middle_data_surf) > 0:\n",
    "        # Split middle period equally into Mid1 and Mid2\n",
    "        if middle_data_surf.argmax().item() > 0:\n",
    "            mid1 = middle_data.isel(time=slice(0, middle_data_surf.argmax().item())).mean(dim='time')\n",
    "            mid2 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mid3 = middle_data.isel(time=slice(middle_data_surf.argmax().item()+1, None)).mean(dim='time')\n",
    "            mld = flattened_MLD[event_id]\n",
    "            max_mld = max_flattened_MLD[event_id]\n",
    "        if middle_data_surf.argmax().item() == 0:\n",
    "            mid1 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mid2 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mid3 = middle_data.isel(time=slice(middle_data_surf.argmax().item()+1, None)).mean(dim='time')\n",
    "            mld = flattened_MLD[event_id]\n",
    "            max_mld = max_flattened_MLD[event_id]\n",
    "        else:\n",
    "            mid1 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mid2 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mid3 = middle_data.isel(time=middle_data_surf.argmax().item()).drop_vars('time')\n",
    "            mld = flattened_MLD[event_id]\n",
    "            max_mld = max_flattened_MLD[event_id]\n",
    "        # Append data\n",
    "        all_pre.append(pre)\n",
    "        all_mid1.append(mid1)\n",
    "        all_mid2.append(mid2)\n",
    "        all_mid3.append(mid3)\n",
    "        all_post.append(post)\n",
    "        mld_ls.append(mld)\n",
    "        max_mld_ls.append(max_mld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be13a9-c40d-47e0-9f29-29aa7f2d76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_da = xr.DataArray(\n",
    "    mld_ls,\n",
    "    dims=[\"event\"],\n",
    "    name=\"MLD\" #mean\n",
    ")\n",
    "\n",
    "max_mld_da = xr.DataArray(\n",
    "    max_mld_ls,\n",
    "    dims=[\"event\"],\n",
    "    name=\"max MLD\" # max\n",
    ")\n",
    "\n",
    "# Combine phases into one DataArray\n",
    "combined = xr.concat(\n",
    "    [\n",
    "        xr.concat(all_pre[:], dim=\"event\"),\n",
    "        xr.concat(all_mid1[:], dim=\"event\"),\n",
    "        xr.concat(all_mid2[:], dim=\"event\"),\n",
    "        xr.concat(all_mid3[:], dim=\"event\"),\n",
    "        xr.concat(all_post[:], dim=\"event\"),\n",
    "    ],\n",
    "    dim=xr.DataArray([\"pre\", \"mid1\", \"mid2\", \"mid3\", \"post\"], dims=\"phase\")\n",
    ")\n",
    "\n",
    "combined = combined.assign_coords(mld=mld_da)\n",
    "combined = combined.assign_coords(max_mld=max_mld_da)\n",
    "\n",
    "combined_dropna = combined.dropna(dim='event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb6447-e984-4b89-bc3a-5e26a336152f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the vertical anomalous temperature structure for each MHW\n",
    "for i in range(combined_dropna.shape[1]):\n",
    "    new_combined = combined_dropna[:,i,:15].transpose()\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    \n",
    "    contour = new_combined.plot.contourf(\n",
    "        ax=ax,\n",
    "        yincrease=False,                # Depth increases downward\n",
    "        cmap='CMRmap',                  # Red-Blue diverging colormap\n",
    "        robust=True,                    # Ignore outliers in color scaling\n",
    "        levels=21, \n",
    "        vmin=0, vmax=0.5,\n",
    "        add_colorbar=False              # We'll add it manually later\n",
    "    )\n",
    "    \n",
    "    \n",
    "    cbar = plt.colorbar(contour, ax=ax, pad=0.02)\n",
    "    cbar.set_label(\"Temperature Anomaly (Â°C)\", fontsize=12)\n",
    "    \n",
    "    ax.grid(True, linestyle=':', alpha=0.5)\n",
    "    plt.axhline(y=0, c='k', linestyle='dashed')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85912f-ce16-4025-84d7-05039294c675",
   "metadata": {},
   "source": [
    "## 3. Grouping MHWs by depth of maximum anomalous warming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f3041-f682-4366-92ff-0555a21edc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_max_var = combined_dropna.max(dim='phase')\n",
    "max_depths = event_max_var.argmax(dim='z_t')\n",
    "z_t_meters = combined_dropna.z_t\n",
    "max_z_t = z_t_meters[max_depths]\n",
    "\n",
    "# # # Bin by depth\n",
    "# depth_bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, np.inf]\n",
    "# depth_labels = [\"0\", \"1000\", \"2000\", \"3000\", \"4000\", \"5000\", \"6000\", \"7000\", \"8000\"]\n",
    "\n",
    "# Bin by depth\n",
    "depth_bins = [0, 1000, 3000, 5000, 7000, np.inf]\n",
    "depth_labels = [\"0\", \"1000\", \"3000\", \"5000\",\"7000\"]\n",
    "\n",
    "depth_category = xr.DataArray(\n",
    "    pd.cut(max_z_t, bins=depth_bins, labels=depth_labels),\n",
    "    dims=[\"event\"],\n",
    "    name=\"depth_category\"\n",
    ")\n",
    "\n",
    "# Group by depth category\n",
    "grouped = combined_dropna.groupby(depth_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be01b4c-0add-4540-9d77-632dbad3e771",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd1ca0-7aa2-406d-b036-ee368251a454",
   "metadata": {},
   "source": [
    "#### Composite plots of MHW vertical anomalous temperature structure grouped by depth of max warming anomaly splitting in 20m intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff44df-8e3a-456b-8a41-f7d465587fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_0 = grouped[\"0\"]\n",
    "ds_1000 = grouped[\"1000\"]\n",
    "ds_3000 = grouped[\"3000\"]\n",
    "ds_5000 = grouped[\"5000\"]\n",
    "ds_7000 = grouped[\"7000\"]\n",
    "\n",
    "print(ds_0.data.shape[1])\n",
    "print(ds_1000.data.shape[1])\n",
    "print(ds_3000.data.shape[1])\n",
    "print(ds_5000.data.shape[1])\n",
    "print(ds_7000.data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6efb7-5bdb-4104-9861-833bb50bf006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mean MLD\n",
    "print(ds_0.mld.mean().item())\n",
    "print(ds_1000.mld.mean().item())\n",
    "print(ds_3000.mld.mean().item())\n",
    "print(ds_5000.mld.mean().item())\n",
    "print(ds_7000.mld.mean().item())\n",
    "\n",
    "# print max MLD\n",
    "max_0 = ds_0.max_mld.mean().item()\n",
    "max_1000 = ds_1000.max_mld.mean().item()\n",
    "max_3000 = ds_3000.max_mld.mean().item()\n",
    "max_5000 = ds_5000.max_mld.mean().item()\n",
    "max_7000 = ds_7000.max_mld.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5bdc41-67c8-443c-b78a-23c4838935dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Dictionary of your depth-binned datasets\n",
    "# depth_datasets = {\n",
    "#     '0-1000m': ds_0,\n",
    "#     '1000-2000m': ds_1000,\n",
    "#     '2000-3000m': ds_2000,\n",
    "#     '3000-4000m': ds_3000,\n",
    "#     '4000-5000m': ds_4000,\n",
    "#     '5000-6000m': ds_5000,\n",
    "#     '6000-7000m': ds_6000,\n",
    "#     # '7000-8000m': ds_7000,\n",
    "#     '8000-9000m': ds_8000\n",
    "# }\n",
    "# Dictionary of your depth-binned datasets\n",
    "depth_datasets = {\n",
    "    '0-1000m': ds_0,\n",
    "    '1000-2000m': ds_1000,\n",
    "    '3000-4000m': ds_3000,\n",
    "    '5000-6000m': ds_5000,\n",
    "    '7000-8000m': ds_7000,\n",
    "}\n",
    "# Create a figure for each depth bin\n",
    "for depth_range, ds in depth_datasets.items():\n",
    "    # Calculate mean across events\n",
    "    new_combined = ds.mean(dim='event')\n",
    "\n",
    "    new_combined = new_combined.isel(z_t = slice(0, 15))\n",
    "    # Convert units if needed (assuming original is in cm)\n",
    "    if new_combined[\"z_t\"].units == \"cm\":\n",
    "        new_combined[\"z_t\"] = new_combined[\"z_t\"] / 100\n",
    "        new_combined[\"z_t\"].attrs[\"units\"] = \"m\"\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "    ax.set_ylim(500, 14000)\n",
    "    # Contour plot\n",
    "    contour = new_combined.transpose().plot.contourf(\n",
    "        ax=ax,\n",
    "        yincrease=False,\n",
    "        robust=True,\n",
    "        levels=26,\n",
    "        cmap='CMRmap',#cmocean.cm.balance,                  # Red-Blue diverging colormap\n",
    "        vmin=0, vmax=0.5,\n",
    "        add_colorbar=False\n",
    "    )\n",
    "    contour = new_combined.transpose().plot.contour(\n",
    "        ax=ax,\n",
    "        yincrease=False,\n",
    "        levels=[0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "        cmap='k',\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    plt.axhline(y=ds.max_mld.mean(), c='lime', linestyle='-')\n",
    "    plt.axhline(y=ds.mld.mean(), c='lime', linestyle='dotted')\n",
    "    # plt.title('')\n",
    "    # Add phase dividers\n",
    "    for x in [0.5, 1.5, 2.5, 3.5]:\n",
    "        ax.axvline(x, color='white', linestyle='--', linewidth=0.75, alpha=0.3)\n",
    "    # # Colorbar\n",
    "    # cbar = plt.colorbar(contour, ax=ax, pad=0.05)\n",
    "    # cbar.formatter = ticker.StrMethodFormatter(\"{x:.2f}\")  # 1 decimal\n",
    "    # cbar.update_ticks()\n",
    "    # plt.axhline(y=\n",
    "    # Labels and title\n",
    "    # ax.set_title(f\"n={ds.data.shape[1]} events\", fontsize=14)\n",
    "    ax.set_xlabel(\"MHW Phase\", fontsize=12)\n",
    "    ax.set_ylabel(\"Depth (m)\", fontsize=12)\n",
    "    ax.set_xticks([0., 1., 2, 3, 4])\n",
    "    ax.set_xticklabels([\"Pre\", \"Lead up\", \"Max\", \"Decline\", \"Post\"], fontsize=10)\n",
    "    # ax.grid(True, linestyle=':', alpha=0.5)\n",
    "    # ax.axhline(y=0, c='k', linestyle='dashed')\n",
    "    # Adjust y-axis tick labels to be divided by 100\n",
    "    yticks = ax.get_yticks()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([f\"{int(tick/100)}\" for tick in yticks])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"mhw_structure_{depth_range.replace('-','_')}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c10fd-1dbc-4db9-b4df-7e325b34d299",
   "metadata": {},
   "source": [
    "#### Bar plot of depth of max warming anomaly MHW counts splitting in 10m intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01414f4-6ef7-4d15-8e44-14c9cca1bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Bar plot of depth of max warming anomaly MHW counts splitting in 10m intervals\n",
    "# event_max_var = combined_dropna.max(dim='phase')\n",
    "# max_depths = event_max_var.argmax(dim='z_t')\n",
    "# z_t_meters = combined_dropna.z_t\n",
    "# max_z_t = z_t_meters[max_depths]\n",
    "\n",
    "# # # Bin by depth\n",
    "# depth_bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, np.inf]\n",
    "# depth_labels = [\"0\", \"1000\", \"2000\", \"3000\", \"4000\", \"5000\", \"6000\", \"7000\"]\n",
    "# # # Bin by depth\n",
    "# # depth_bins = [0, 1000, 3000, 5000, 7000, np.inf]\n",
    "# # depth_labels = [\"0\", \"1000\", \"3000\", \"5000\",\"7000\"]\n",
    "\n",
    "# depth_category = xr.DataArray(\n",
    "#     pd.cut(max_z_t, bins=depth_bins, labels=depth_labels),\n",
    "#     dims=[\"event\"],\n",
    "#     name=\"depth_category\"\n",
    "# )\n",
    "\n",
    "# # Group by depth category\n",
    "# grouped = combined_dropna.groupby(depth_category)\n",
    "\n",
    "# ds_0 = grouped[\"0\"]\n",
    "# ds_1000 = grouped[\"1000\"]\n",
    "# ds_2000 = grouped[\"2000\"]\n",
    "# ds_3000 = grouped[\"3000\"]\n",
    "# ds_4000 = grouped[\"4000\"]\n",
    "# ds_5000 = grouped[\"5000\"]\n",
    "# ds_6000 = grouped[\"6000\"]\n",
    "# ds_7000 = grouped[\"7000\"]\n",
    "\n",
    "# print(ds_0.data.shape[1])\n",
    "# print(ds_1000.data.shape[1])\n",
    "# print(ds_2000.data.shape[1])\n",
    "# print(ds_3000.data.shape[1])\n",
    "# print(ds_4000.data.shape[1])\n",
    "# print(ds_5000.data.shape[1])\n",
    "# print(ds_6000.data.shape[1])\n",
    "# print(ds_7000.data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b00b60-38ce-42ce-9e31-5d2839589db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Depth range to number of events mapping\n",
    "# depth_counts = {\n",
    "#     '0-10m': ds_0.data.shape[1],\n",
    "#     '10-20m': ds_1000.data.shape[1],\n",
    "#     '20-30m': ds_2000.data.shape[1],\n",
    "#     '30-40m': ds_3000.data.shape[1],\n",
    "#     '40-50m': ds_4000.data.shape[1],\n",
    "#     '50-60m': ds_5000.data.shape[1],\n",
    "#     '60-70m': ds_6000.data.shape[1],\n",
    "#     '70-80m': ds_7000.data.shape[1],\n",
    "#     '80-90m': ds_8000.data.shape[1],\n",
    "#     # Add more if needed\n",
    "# }\n",
    "\n",
    "# # Extract labels and counts\n",
    "# bin_labels = list(depth_counts.keys())\n",
    "# counts = list(depth_counts.values())\n",
    "\n",
    "# # Create horizontal bar plot\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# bars = plt.barh(bin_labels, counts, color='teal')\n",
    "# # Add count labels next to bars\n",
    "# for bar in bars:\n",
    "#     width = bar.get_width()\n",
    "#     plt.text(width + 1, bar.get_y() + bar.get_height() / 2,\n",
    "#              f'{width}', va='center', fontsize=12)\n",
    "\n",
    "# # Plot formatting\n",
    "# plt.xlabel('Number of Events')\n",
    "# plt.ylabel('Depth Maximum (m)')\n",
    "# plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "# plt.tight_layout()\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436023c0-f1f4-4292-b295-e8e5223bcf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth range to number of events mapping\n",
    "depth_counts = {\n",
    "    '0-10m': ds_0.data.shape[1],\n",
    "    '10-20m': ds_1000.data.shape[1],\n",
    "    '20-30m': ds_2000.data.shape[1],\n",
    "    '30-40m': ds_3000.data.shape[1],\n",
    "    '40-50m': ds_4000.data.shape[1],\n",
    "    '50-60m': ds_5000.data.shape[1],\n",
    "    '60-70m': ds_6000.data.shape[1],\n",
    "    '70-80m': ds_7000.data.shape[1],\n",
    "    '80-90m': ds_8000.data.shape[1],\n",
    "}\n",
    "\n",
    "# Extract labels and counts\n",
    "bin_labels = list(depth_counts.keys())\n",
    "counts = list(depth_counts.values())\n",
    "\n",
    "# Convert to percentages\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "# Create horizontal bar plot\n",
    "plt.figure(figsize=(3, 3))\n",
    "bars = plt.barh(bin_labels, percentages, color='teal')\n",
    "\n",
    "# Add percentage labels next to bars\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    plt.text(pct + 0.5, bar.get_y() + bar.get_height() / 2,\n",
    "             f'{pct:.1f}%', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot formatting\n",
    "plt.xlabel('Percentage of Events', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e09a4-6bb2-42c2-b70f-b0c82673a6eb",
   "metadata": {},
   "source": [
    "#### Bar plot of depth of max warming anomaly MHW counts splitting in 20m intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca413b20-b226-4279-b24d-c70d4bbbc463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth range to number of events mapping\n",
    "depth_counts = {\n",
    "    '0-10m': ds_0.data.shape[1],\n",
    "    '10-30m': ds_1000.data.shape[1],\n",
    "    # '20-30m': ds_2000.data.shape[1],\n",
    "    '30-50m': ds_3000.data.shape[1],\n",
    "    # '40-50m': ds_4000.data.shape[1],\n",
    "    '50-70m': ds_5000.data.shape[1],\n",
    "    # '60-70m': ds_6000.data.shape[1],\n",
    "    '70+m': ds_7000.data.shape[1],\n",
    "    # '80-90m': ds_8000.data.shape[1],\n",
    "}\n",
    "\n",
    "# Extract labels and counts\n",
    "bin_labels = list(depth_counts.keys())\n",
    "counts = list(depth_counts.values())\n",
    "\n",
    "# Convert to percentages\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "# Create horizontal bar plot\n",
    "plt.figure(figsize=(3, 3))\n",
    "bars = plt.barh(bin_labels, percentages, color='teal')\n",
    "\n",
    "# Add percentage labels next to bars\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    plt.text(pct + 0.5, bar.get_y() + bar.get_height() / 2,\n",
    "             f'{pct:.1f}%', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot formatting\n",
    "plt.xlabel('Percentage of Events', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b9ea0-a24c-4932-99b5-fb209444a591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2025a",
   "language": "python",
   "name": "npl-2025a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
